{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2821f3-ea04-4850-b684-2a042615e36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ldm.data.audio_landscape import AudioTrain\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356028ab-a66f-47ec-80d0-f536cfb2fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"logs/2022-09-28T20-39-59_lsun_churches-ldm-kl-8/checkpoints/last.ckpt\"\n",
    "\n",
    "a = torch.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fc4a2c4-48f9-438f-8a8e-42ae40c658af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7167c757-f09c-465c-a247-d7e8401b3267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['betas', 'alphas_cumprod', 'alphas_cumprod_prev', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod', 'log_one_minus_alphas_cumprod', 'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod', 'posterior_variance', 'posterior_log_variance_clipped', 'posterior_mean_coef1', 'posterior_mean_coef2', 'scale_factor', 'model.diffusion_model.input_proj.proj.0.weight', 'model.diffusion_model.input_proj.proj.0.bias', 'model.diffusion_model.output_proj.proj.0.weight', 'model.diffusion_model.output_proj.proj.0.bias', 'model.diffusion_model.encoderlayer_0.time_embed.0.weight', 'model.diffusion_model.encoderlayer_0.time_embed.0.bias', 'model.diffusion_model.encoderlayer_0.time_embed.2.weight', 'model.diffusion_model.encoderlayer_0.time_embed.2.bias', 'model.diffusion_model.encoderlayer_0.blocks.0.norm1.weight', 'model.diffusion_model.encoderlayer_0.blocks.0.norm1.bias', 'model.diffusion_model.encoderlayer_0.blocks.0.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_0.blocks.0.attn.relative_position_index', 'model.diffusion_model.encoderlayer_0.blocks.0.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_0.blocks.0.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_0.blocks.0.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_0.blocks.0.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_0.blocks.0.attn.proj.weight', 'model.diffusion_model.encoderlayer_0.blocks.0.attn.proj.bias', 'model.diffusion_model.encoderlayer_0.blocks.0.norm2.weight', 'model.diffusion_model.encoderlayer_0.blocks.0.norm2.bias', 'model.diffusion_model.encoderlayer_0.blocks.0.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_0.blocks.0.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_0.blocks.0.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_0.blocks.0.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_0.blocks.0.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_0.blocks.0.mlp.linear2.0.bias', 'model.diffusion_model.dowsample_0.conv.0.weight', 'model.diffusion_model.dowsample_0.conv.0.bias', 'model.diffusion_model.encoderlayer_1.time_embed.0.weight', 'model.diffusion_model.encoderlayer_1.time_embed.0.bias', 'model.diffusion_model.encoderlayer_1.time_embed.2.weight', 'model.diffusion_model.encoderlayer_1.time_embed.2.bias', 'model.diffusion_model.encoderlayer_1.blocks.0.norm1.weight', 'model.diffusion_model.encoderlayer_1.blocks.0.norm1.bias', 'model.diffusion_model.encoderlayer_1.blocks.0.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_1.blocks.0.attn.relative_position_index', 'model.diffusion_model.encoderlayer_1.blocks.0.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_1.blocks.0.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_1.blocks.0.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_1.blocks.0.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_1.blocks.0.attn.proj.weight', 'model.diffusion_model.encoderlayer_1.blocks.0.attn.proj.bias', 'model.diffusion_model.encoderlayer_1.blocks.0.norm2.weight', 'model.diffusion_model.encoderlayer_1.blocks.0.norm2.bias', 'model.diffusion_model.encoderlayer_1.blocks.0.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_1.blocks.0.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_1.blocks.0.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_1.blocks.0.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_1.blocks.0.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_1.blocks.0.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_1.blocks.1.norm1.weight', 'model.diffusion_model.encoderlayer_1.blocks.1.norm1.bias', 'model.diffusion_model.encoderlayer_1.blocks.1.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_1.blocks.1.attn.relative_position_index', 'model.diffusion_model.encoderlayer_1.blocks.1.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_1.blocks.1.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_1.blocks.1.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_1.blocks.1.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_1.blocks.1.attn.proj.weight', 'model.diffusion_model.encoderlayer_1.blocks.1.attn.proj.bias', 'model.diffusion_model.encoderlayer_1.blocks.1.norm2.weight', 'model.diffusion_model.encoderlayer_1.blocks.1.norm2.bias', 'model.diffusion_model.encoderlayer_1.blocks.1.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_1.blocks.1.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_1.blocks.1.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_1.blocks.1.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_1.blocks.1.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_1.blocks.1.mlp.linear2.0.bias', 'model.diffusion_model.dowsample_1.conv.0.weight', 'model.diffusion_model.dowsample_1.conv.0.bias', 'model.diffusion_model.encoderlayer_2.time_embed.0.weight', 'model.diffusion_model.encoderlayer_2.time_embed.0.bias', 'model.diffusion_model.encoderlayer_2.time_embed.2.weight', 'model.diffusion_model.encoderlayer_2.time_embed.2.bias', 'model.diffusion_model.encoderlayer_2.blocks.0.norm1.weight', 'model.diffusion_model.encoderlayer_2.blocks.0.norm1.bias', 'model.diffusion_model.encoderlayer_2.blocks.0.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_2.blocks.0.attn.relative_position_index', 'model.diffusion_model.encoderlayer_2.blocks.0.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_2.blocks.0.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_2.blocks.0.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_2.blocks.0.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_2.blocks.0.attn.proj.weight', 'model.diffusion_model.encoderlayer_2.blocks.0.attn.proj.bias', 'model.diffusion_model.encoderlayer_2.blocks.0.norm2.weight', 'model.diffusion_model.encoderlayer_2.blocks.0.norm2.bias', 'model.diffusion_model.encoderlayer_2.blocks.0.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.0.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.0.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.0.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.0.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.0.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.1.norm1.weight', 'model.diffusion_model.encoderlayer_2.blocks.1.norm1.bias', 'model.diffusion_model.encoderlayer_2.blocks.1.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_2.blocks.1.attn.relative_position_index', 'model.diffusion_model.encoderlayer_2.blocks.1.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_2.blocks.1.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_2.blocks.1.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_2.blocks.1.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_2.blocks.1.attn.proj.weight', 'model.diffusion_model.encoderlayer_2.blocks.1.attn.proj.bias', 'model.diffusion_model.encoderlayer_2.blocks.1.norm2.weight', 'model.diffusion_model.encoderlayer_2.blocks.1.norm2.bias', 'model.diffusion_model.encoderlayer_2.blocks.1.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.1.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.1.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.1.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.1.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.1.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.2.norm1.weight', 'model.diffusion_model.encoderlayer_2.blocks.2.norm1.bias', 'model.diffusion_model.encoderlayer_2.blocks.2.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_2.blocks.2.attn.relative_position_index', 'model.diffusion_model.encoderlayer_2.blocks.2.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_2.blocks.2.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_2.blocks.2.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_2.blocks.2.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_2.blocks.2.attn.proj.weight', 'model.diffusion_model.encoderlayer_2.blocks.2.attn.proj.bias', 'model.diffusion_model.encoderlayer_2.blocks.2.norm2.weight', 'model.diffusion_model.encoderlayer_2.blocks.2.norm2.bias', 'model.diffusion_model.encoderlayer_2.blocks.2.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.2.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.2.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.2.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.2.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.2.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.3.norm1.weight', 'model.diffusion_model.encoderlayer_2.blocks.3.norm1.bias', 'model.diffusion_model.encoderlayer_2.blocks.3.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_2.blocks.3.attn.relative_position_index', 'model.diffusion_model.encoderlayer_2.blocks.3.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_2.blocks.3.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_2.blocks.3.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_2.blocks.3.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_2.blocks.3.attn.proj.weight', 'model.diffusion_model.encoderlayer_2.blocks.3.attn.proj.bias', 'model.diffusion_model.encoderlayer_2.blocks.3.norm2.weight', 'model.diffusion_model.encoderlayer_2.blocks.3.norm2.bias', 'model.diffusion_model.encoderlayer_2.blocks.3.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.3.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.3.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.3.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.3.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.3.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.4.norm1.weight', 'model.diffusion_model.encoderlayer_2.blocks.4.norm1.bias', 'model.diffusion_model.encoderlayer_2.blocks.4.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_2.blocks.4.attn.relative_position_index', 'model.diffusion_model.encoderlayer_2.blocks.4.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_2.blocks.4.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_2.blocks.4.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_2.blocks.4.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_2.blocks.4.attn.proj.weight', 'model.diffusion_model.encoderlayer_2.blocks.4.attn.proj.bias', 'model.diffusion_model.encoderlayer_2.blocks.4.norm2.weight', 'model.diffusion_model.encoderlayer_2.blocks.4.norm2.bias', 'model.diffusion_model.encoderlayer_2.blocks.4.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.4.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.4.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.4.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.4.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.4.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.5.norm1.weight', 'model.diffusion_model.encoderlayer_2.blocks.5.norm1.bias', 'model.diffusion_model.encoderlayer_2.blocks.5.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_2.blocks.5.attn.relative_position_index', 'model.diffusion_model.encoderlayer_2.blocks.5.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_2.blocks.5.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_2.blocks.5.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_2.blocks.5.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_2.blocks.5.attn.proj.weight', 'model.diffusion_model.encoderlayer_2.blocks.5.attn.proj.bias', 'model.diffusion_model.encoderlayer_2.blocks.5.norm2.weight', 'model.diffusion_model.encoderlayer_2.blocks.5.norm2.bias', 'model.diffusion_model.encoderlayer_2.blocks.5.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.5.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.5.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.5.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.5.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.5.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.6.norm1.weight', 'model.diffusion_model.encoderlayer_2.blocks.6.norm1.bias', 'model.diffusion_model.encoderlayer_2.blocks.6.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_2.blocks.6.attn.relative_position_index', 'model.diffusion_model.encoderlayer_2.blocks.6.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_2.blocks.6.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_2.blocks.6.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_2.blocks.6.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_2.blocks.6.attn.proj.weight', 'model.diffusion_model.encoderlayer_2.blocks.6.attn.proj.bias', 'model.diffusion_model.encoderlayer_2.blocks.6.norm2.weight', 'model.diffusion_model.encoderlayer_2.blocks.6.norm2.bias', 'model.diffusion_model.encoderlayer_2.blocks.6.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.6.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.6.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.6.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.6.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.6.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.7.norm1.weight', 'model.diffusion_model.encoderlayer_2.blocks.7.norm1.bias', 'model.diffusion_model.encoderlayer_2.blocks.7.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_2.blocks.7.attn.relative_position_index', 'model.diffusion_model.encoderlayer_2.blocks.7.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_2.blocks.7.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_2.blocks.7.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_2.blocks.7.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_2.blocks.7.attn.proj.weight', 'model.diffusion_model.encoderlayer_2.blocks.7.attn.proj.bias', 'model.diffusion_model.encoderlayer_2.blocks.7.norm2.weight', 'model.diffusion_model.encoderlayer_2.blocks.7.norm2.bias', 'model.diffusion_model.encoderlayer_2.blocks.7.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.7.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.7.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.7.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_2.blocks.7.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_2.blocks.7.mlp.linear2.0.bias', 'model.diffusion_model.dowsample_2.conv.0.weight', 'model.diffusion_model.dowsample_2.conv.0.bias', 'model.diffusion_model.encoderlayer_3.time_embed.0.weight', 'model.diffusion_model.encoderlayer_3.time_embed.0.bias', 'model.diffusion_model.encoderlayer_3.time_embed.2.weight', 'model.diffusion_model.encoderlayer_3.time_embed.2.bias', 'model.diffusion_model.encoderlayer_3.blocks.0.norm1.weight', 'model.diffusion_model.encoderlayer_3.blocks.0.norm1.bias', 'model.diffusion_model.encoderlayer_3.blocks.0.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_3.blocks.0.attn.relative_position_index', 'model.diffusion_model.encoderlayer_3.blocks.0.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_3.blocks.0.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_3.blocks.0.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_3.blocks.0.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_3.blocks.0.attn.proj.weight', 'model.diffusion_model.encoderlayer_3.blocks.0.attn.proj.bias', 'model.diffusion_model.encoderlayer_3.blocks.0.norm2.weight', 'model.diffusion_model.encoderlayer_3.blocks.0.norm2.bias', 'model.diffusion_model.encoderlayer_3.blocks.0.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.0.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.0.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.0.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.0.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.0.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.1.norm1.weight', 'model.diffusion_model.encoderlayer_3.blocks.1.norm1.bias', 'model.diffusion_model.encoderlayer_3.blocks.1.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_3.blocks.1.attn.relative_position_index', 'model.diffusion_model.encoderlayer_3.blocks.1.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_3.blocks.1.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_3.blocks.1.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_3.blocks.1.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_3.blocks.1.attn.proj.weight', 'model.diffusion_model.encoderlayer_3.blocks.1.attn.proj.bias', 'model.diffusion_model.encoderlayer_3.blocks.1.norm2.weight', 'model.diffusion_model.encoderlayer_3.blocks.1.norm2.bias', 'model.diffusion_model.encoderlayer_3.blocks.1.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.1.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.1.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.1.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.1.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.1.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.2.norm1.weight', 'model.diffusion_model.encoderlayer_3.blocks.2.norm1.bias', 'model.diffusion_model.encoderlayer_3.blocks.2.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_3.blocks.2.attn.relative_position_index', 'model.diffusion_model.encoderlayer_3.blocks.2.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_3.blocks.2.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_3.blocks.2.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_3.blocks.2.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_3.blocks.2.attn.proj.weight', 'model.diffusion_model.encoderlayer_3.blocks.2.attn.proj.bias', 'model.diffusion_model.encoderlayer_3.blocks.2.norm2.weight', 'model.diffusion_model.encoderlayer_3.blocks.2.norm2.bias', 'model.diffusion_model.encoderlayer_3.blocks.2.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.2.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.2.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.2.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.2.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.2.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.3.norm1.weight', 'model.diffusion_model.encoderlayer_3.blocks.3.norm1.bias', 'model.diffusion_model.encoderlayer_3.blocks.3.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_3.blocks.3.attn.relative_position_index', 'model.diffusion_model.encoderlayer_3.blocks.3.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_3.blocks.3.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_3.blocks.3.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_3.blocks.3.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_3.blocks.3.attn.proj.weight', 'model.diffusion_model.encoderlayer_3.blocks.3.attn.proj.bias', 'model.diffusion_model.encoderlayer_3.blocks.3.norm2.weight', 'model.diffusion_model.encoderlayer_3.blocks.3.norm2.bias', 'model.diffusion_model.encoderlayer_3.blocks.3.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.3.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.3.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.3.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.3.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.3.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.4.norm1.weight', 'model.diffusion_model.encoderlayer_3.blocks.4.norm1.bias', 'model.diffusion_model.encoderlayer_3.blocks.4.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_3.blocks.4.attn.relative_position_index', 'model.diffusion_model.encoderlayer_3.blocks.4.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_3.blocks.4.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_3.blocks.4.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_3.blocks.4.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_3.blocks.4.attn.proj.weight', 'model.diffusion_model.encoderlayer_3.blocks.4.attn.proj.bias', 'model.diffusion_model.encoderlayer_3.blocks.4.norm2.weight', 'model.diffusion_model.encoderlayer_3.blocks.4.norm2.bias', 'model.diffusion_model.encoderlayer_3.blocks.4.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.4.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.4.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.4.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.4.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.4.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.5.norm1.weight', 'model.diffusion_model.encoderlayer_3.blocks.5.norm1.bias', 'model.diffusion_model.encoderlayer_3.blocks.5.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_3.blocks.5.attn.relative_position_index', 'model.diffusion_model.encoderlayer_3.blocks.5.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_3.blocks.5.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_3.blocks.5.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_3.blocks.5.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_3.blocks.5.attn.proj.weight', 'model.diffusion_model.encoderlayer_3.blocks.5.attn.proj.bias', 'model.diffusion_model.encoderlayer_3.blocks.5.norm2.weight', 'model.diffusion_model.encoderlayer_3.blocks.5.norm2.bias', 'model.diffusion_model.encoderlayer_3.blocks.5.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.5.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.5.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.5.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.5.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.5.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.6.norm1.weight', 'model.diffusion_model.encoderlayer_3.blocks.6.norm1.bias', 'model.diffusion_model.encoderlayer_3.blocks.6.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_3.blocks.6.attn.relative_position_index', 'model.diffusion_model.encoderlayer_3.blocks.6.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_3.blocks.6.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_3.blocks.6.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_3.blocks.6.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_3.blocks.6.attn.proj.weight', 'model.diffusion_model.encoderlayer_3.blocks.6.attn.proj.bias', 'model.diffusion_model.encoderlayer_3.blocks.6.norm2.weight', 'model.diffusion_model.encoderlayer_3.blocks.6.norm2.bias', 'model.diffusion_model.encoderlayer_3.blocks.6.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.6.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.6.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.6.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.6.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.6.mlp.linear2.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.7.norm1.weight', 'model.diffusion_model.encoderlayer_3.blocks.7.norm1.bias', 'model.diffusion_model.encoderlayer_3.blocks.7.attn.relative_position_bias_table', 'model.diffusion_model.encoderlayer_3.blocks.7.attn.relative_position_index', 'model.diffusion_model.encoderlayer_3.blocks.7.attn.qkv.to_q.weight', 'model.diffusion_model.encoderlayer_3.blocks.7.attn.qkv.to_q.bias', 'model.diffusion_model.encoderlayer_3.blocks.7.attn.qkv.to_kv.weight', 'model.diffusion_model.encoderlayer_3.blocks.7.attn.qkv.to_kv.bias', 'model.diffusion_model.encoderlayer_3.blocks.7.attn.proj.weight', 'model.diffusion_model.encoderlayer_3.blocks.7.attn.proj.bias', 'model.diffusion_model.encoderlayer_3.blocks.7.norm2.weight', 'model.diffusion_model.encoderlayer_3.blocks.7.norm2.bias', 'model.diffusion_model.encoderlayer_3.blocks.7.mlp.linear1.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.7.mlp.linear1.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.7.mlp.dwconv.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.7.mlp.dwconv.0.bias', 'model.diffusion_model.encoderlayer_3.blocks.7.mlp.linear2.0.weight', 'model.diffusion_model.encoderlayer_3.blocks.7.mlp.linear2.0.bias', 'model.diffusion_model.dowsample_3.conv.0.weight', 'model.diffusion_model.dowsample_3.conv.0.bias', 'model.diffusion_model.conv.time_embed.0.weight', 'model.diffusion_model.conv.time_embed.0.bias', 'model.diffusion_model.conv.time_embed.2.weight', 'model.diffusion_model.conv.time_embed.2.bias', 'model.diffusion_model.conv.blocks.0.norm1.weight', 'model.diffusion_model.conv.blocks.0.norm1.bias', 'model.diffusion_model.conv.blocks.0.attn.relative_position_bias_table', 'model.diffusion_model.conv.blocks.0.attn.relative_position_index', 'model.diffusion_model.conv.blocks.0.attn.qkv.to_q.weight', 'model.diffusion_model.conv.blocks.0.attn.qkv.to_q.bias', 'model.diffusion_model.conv.blocks.0.attn.qkv.to_kv.weight', 'model.diffusion_model.conv.blocks.0.attn.qkv.to_kv.bias', 'model.diffusion_model.conv.blocks.0.attn.proj.weight', 'model.diffusion_model.conv.blocks.0.attn.proj.bias', 'model.diffusion_model.conv.blocks.0.norm2.weight', 'model.diffusion_model.conv.blocks.0.norm2.bias', 'model.diffusion_model.conv.blocks.0.mlp.linear1.0.weight', 'model.diffusion_model.conv.blocks.0.mlp.linear1.0.bias', 'model.diffusion_model.conv.blocks.0.mlp.dwconv.0.weight', 'model.diffusion_model.conv.blocks.0.mlp.dwconv.0.bias', 'model.diffusion_model.conv.blocks.0.mlp.linear2.0.weight', 'model.diffusion_model.conv.blocks.0.mlp.linear2.0.bias', 'model.diffusion_model.conv.blocks.1.norm1.weight', 'model.diffusion_model.conv.blocks.1.norm1.bias', 'model.diffusion_model.conv.blocks.1.attn.relative_position_bias_table', 'model.diffusion_model.conv.blocks.1.attn.relative_position_index', 'model.diffusion_model.conv.blocks.1.attn.qkv.to_q.weight', 'model.diffusion_model.conv.blocks.1.attn.qkv.to_q.bias', 'model.diffusion_model.conv.blocks.1.attn.qkv.to_kv.weight', 'model.diffusion_model.conv.blocks.1.attn.qkv.to_kv.bias', 'model.diffusion_model.conv.blocks.1.attn.proj.weight', 'model.diffusion_model.conv.blocks.1.attn.proj.bias', 'model.diffusion_model.conv.blocks.1.norm2.weight', 'model.diffusion_model.conv.blocks.1.norm2.bias', 'model.diffusion_model.conv.blocks.1.mlp.linear1.0.weight', 'model.diffusion_model.conv.blocks.1.mlp.linear1.0.bias', 'model.diffusion_model.conv.blocks.1.mlp.dwconv.0.weight', 'model.diffusion_model.conv.blocks.1.mlp.dwconv.0.bias', 'model.diffusion_model.conv.blocks.1.mlp.linear2.0.weight', 'model.diffusion_model.conv.blocks.1.mlp.linear2.0.bias', 'model.diffusion_model.upsample_0.deconv.0.weight', 'model.diffusion_model.upsample_0.deconv.0.bias', 'model.diffusion_model.decoderlayer_0.time_embed.0.weight', 'model.diffusion_model.decoderlayer_0.time_embed.0.bias', 'model.diffusion_model.decoderlayer_0.time_embed.2.weight', 'model.diffusion_model.decoderlayer_0.time_embed.2.bias', 'model.diffusion_model.decoderlayer_0.blocks.0.norm1.weight', 'model.diffusion_model.decoderlayer_0.blocks.0.norm1.bias', 'model.diffusion_model.decoderlayer_0.blocks.0.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_0.blocks.0.attn.relative_position_index', 'model.diffusion_model.decoderlayer_0.blocks.0.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_0.blocks.0.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_0.blocks.0.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_0.blocks.0.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_0.blocks.0.attn.proj.weight', 'model.diffusion_model.decoderlayer_0.blocks.0.attn.proj.bias', 'model.diffusion_model.decoderlayer_0.blocks.0.norm2.weight', 'model.diffusion_model.decoderlayer_0.blocks.0.norm2.bias', 'model.diffusion_model.decoderlayer_0.blocks.0.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.0.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.0.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.0.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.0.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.0.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.1.norm1.weight', 'model.diffusion_model.decoderlayer_0.blocks.1.norm1.bias', 'model.diffusion_model.decoderlayer_0.blocks.1.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_0.blocks.1.attn.relative_position_index', 'model.diffusion_model.decoderlayer_0.blocks.1.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_0.blocks.1.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_0.blocks.1.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_0.blocks.1.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_0.blocks.1.attn.proj.weight', 'model.diffusion_model.decoderlayer_0.blocks.1.attn.proj.bias', 'model.diffusion_model.decoderlayer_0.blocks.1.norm2.weight', 'model.diffusion_model.decoderlayer_0.blocks.1.norm2.bias', 'model.diffusion_model.decoderlayer_0.blocks.1.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.1.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.1.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.1.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.1.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.1.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.2.norm1.weight', 'model.diffusion_model.decoderlayer_0.blocks.2.norm1.bias', 'model.diffusion_model.decoderlayer_0.blocks.2.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_0.blocks.2.attn.relative_position_index', 'model.diffusion_model.decoderlayer_0.blocks.2.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_0.blocks.2.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_0.blocks.2.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_0.blocks.2.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_0.blocks.2.attn.proj.weight', 'model.diffusion_model.decoderlayer_0.blocks.2.attn.proj.bias', 'model.diffusion_model.decoderlayer_0.blocks.2.norm2.weight', 'model.diffusion_model.decoderlayer_0.blocks.2.norm2.bias', 'model.diffusion_model.decoderlayer_0.blocks.2.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.2.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.2.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.2.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.2.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.2.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.3.norm1.weight', 'model.diffusion_model.decoderlayer_0.blocks.3.norm1.bias', 'model.diffusion_model.decoderlayer_0.blocks.3.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_0.blocks.3.attn.relative_position_index', 'model.diffusion_model.decoderlayer_0.blocks.3.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_0.blocks.3.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_0.blocks.3.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_0.blocks.3.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_0.blocks.3.attn.proj.weight', 'model.diffusion_model.decoderlayer_0.blocks.3.attn.proj.bias', 'model.diffusion_model.decoderlayer_0.blocks.3.norm2.weight', 'model.diffusion_model.decoderlayer_0.blocks.3.norm2.bias', 'model.diffusion_model.decoderlayer_0.blocks.3.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.3.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.3.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.3.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.3.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.3.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.4.norm1.weight', 'model.diffusion_model.decoderlayer_0.blocks.4.norm1.bias', 'model.diffusion_model.decoderlayer_0.blocks.4.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_0.blocks.4.attn.relative_position_index', 'model.diffusion_model.decoderlayer_0.blocks.4.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_0.blocks.4.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_0.blocks.4.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_0.blocks.4.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_0.blocks.4.attn.proj.weight', 'model.diffusion_model.decoderlayer_0.blocks.4.attn.proj.bias', 'model.diffusion_model.decoderlayer_0.blocks.4.norm2.weight', 'model.diffusion_model.decoderlayer_0.blocks.4.norm2.bias', 'model.diffusion_model.decoderlayer_0.blocks.4.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.4.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.4.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.4.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.4.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.4.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.5.norm1.weight', 'model.diffusion_model.decoderlayer_0.blocks.5.norm1.bias', 'model.diffusion_model.decoderlayer_0.blocks.5.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_0.blocks.5.attn.relative_position_index', 'model.diffusion_model.decoderlayer_0.blocks.5.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_0.blocks.5.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_0.blocks.5.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_0.blocks.5.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_0.blocks.5.attn.proj.weight', 'model.diffusion_model.decoderlayer_0.blocks.5.attn.proj.bias', 'model.diffusion_model.decoderlayer_0.blocks.5.norm2.weight', 'model.diffusion_model.decoderlayer_0.blocks.5.norm2.bias', 'model.diffusion_model.decoderlayer_0.blocks.5.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.5.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.5.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.5.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.5.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.5.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.6.norm1.weight', 'model.diffusion_model.decoderlayer_0.blocks.6.norm1.bias', 'model.diffusion_model.decoderlayer_0.blocks.6.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_0.blocks.6.attn.relative_position_index', 'model.diffusion_model.decoderlayer_0.blocks.6.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_0.blocks.6.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_0.blocks.6.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_0.blocks.6.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_0.blocks.6.attn.proj.weight', 'model.diffusion_model.decoderlayer_0.blocks.6.attn.proj.bias', 'model.diffusion_model.decoderlayer_0.blocks.6.norm2.weight', 'model.diffusion_model.decoderlayer_0.blocks.6.norm2.bias', 'model.diffusion_model.decoderlayer_0.blocks.6.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.6.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.6.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.6.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.6.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.6.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.7.norm1.weight', 'model.diffusion_model.decoderlayer_0.blocks.7.norm1.bias', 'model.diffusion_model.decoderlayer_0.blocks.7.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_0.blocks.7.attn.relative_position_index', 'model.diffusion_model.decoderlayer_0.blocks.7.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_0.blocks.7.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_0.blocks.7.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_0.blocks.7.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_0.blocks.7.attn.proj.weight', 'model.diffusion_model.decoderlayer_0.blocks.7.attn.proj.bias', 'model.diffusion_model.decoderlayer_0.blocks.7.norm2.weight', 'model.diffusion_model.decoderlayer_0.blocks.7.norm2.bias', 'model.diffusion_model.decoderlayer_0.blocks.7.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.7.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.7.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.7.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_0.blocks.7.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_0.blocks.7.mlp.linear2.0.bias', 'model.diffusion_model.upsample_1.deconv.0.weight', 'model.diffusion_model.upsample_1.deconv.0.bias', 'model.diffusion_model.decoderlayer_1.time_embed.0.weight', 'model.diffusion_model.decoderlayer_1.time_embed.0.bias', 'model.diffusion_model.decoderlayer_1.time_embed.2.weight', 'model.diffusion_model.decoderlayer_1.time_embed.2.bias', 'model.diffusion_model.decoderlayer_1.blocks.0.norm1.weight', 'model.diffusion_model.decoderlayer_1.blocks.0.norm1.bias', 'model.diffusion_model.decoderlayer_1.blocks.0.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_1.blocks.0.attn.relative_position_index', 'model.diffusion_model.decoderlayer_1.blocks.0.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_1.blocks.0.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_1.blocks.0.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_1.blocks.0.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_1.blocks.0.attn.proj.weight', 'model.diffusion_model.decoderlayer_1.blocks.0.attn.proj.bias', 'model.diffusion_model.decoderlayer_1.blocks.0.norm2.weight', 'model.diffusion_model.decoderlayer_1.blocks.0.norm2.bias', 'model.diffusion_model.decoderlayer_1.blocks.0.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.0.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.0.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.0.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.0.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.0.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.1.norm1.weight', 'model.diffusion_model.decoderlayer_1.blocks.1.norm1.bias', 'model.diffusion_model.decoderlayer_1.blocks.1.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_1.blocks.1.attn.relative_position_index', 'model.diffusion_model.decoderlayer_1.blocks.1.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_1.blocks.1.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_1.blocks.1.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_1.blocks.1.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_1.blocks.1.attn.proj.weight', 'model.diffusion_model.decoderlayer_1.blocks.1.attn.proj.bias', 'model.diffusion_model.decoderlayer_1.blocks.1.norm2.weight', 'model.diffusion_model.decoderlayer_1.blocks.1.norm2.bias', 'model.diffusion_model.decoderlayer_1.blocks.1.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.1.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.1.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.1.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.1.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.1.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.2.norm1.weight', 'model.diffusion_model.decoderlayer_1.blocks.2.norm1.bias', 'model.diffusion_model.decoderlayer_1.blocks.2.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_1.blocks.2.attn.relative_position_index', 'model.diffusion_model.decoderlayer_1.blocks.2.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_1.blocks.2.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_1.blocks.2.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_1.blocks.2.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_1.blocks.2.attn.proj.weight', 'model.diffusion_model.decoderlayer_1.blocks.2.attn.proj.bias', 'model.diffusion_model.decoderlayer_1.blocks.2.norm2.weight', 'model.diffusion_model.decoderlayer_1.blocks.2.norm2.bias', 'model.diffusion_model.decoderlayer_1.blocks.2.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.2.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.2.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.2.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.2.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.2.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.3.norm1.weight', 'model.diffusion_model.decoderlayer_1.blocks.3.norm1.bias', 'model.diffusion_model.decoderlayer_1.blocks.3.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_1.blocks.3.attn.relative_position_index', 'model.diffusion_model.decoderlayer_1.blocks.3.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_1.blocks.3.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_1.blocks.3.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_1.blocks.3.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_1.blocks.3.attn.proj.weight', 'model.diffusion_model.decoderlayer_1.blocks.3.attn.proj.bias', 'model.diffusion_model.decoderlayer_1.blocks.3.norm2.weight', 'model.diffusion_model.decoderlayer_1.blocks.3.norm2.bias', 'model.diffusion_model.decoderlayer_1.blocks.3.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.3.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.3.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.3.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.3.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.3.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.4.norm1.weight', 'model.diffusion_model.decoderlayer_1.blocks.4.norm1.bias', 'model.diffusion_model.decoderlayer_1.blocks.4.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_1.blocks.4.attn.relative_position_index', 'model.diffusion_model.decoderlayer_1.blocks.4.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_1.blocks.4.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_1.blocks.4.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_1.blocks.4.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_1.blocks.4.attn.proj.weight', 'model.diffusion_model.decoderlayer_1.blocks.4.attn.proj.bias', 'model.diffusion_model.decoderlayer_1.blocks.4.norm2.weight', 'model.diffusion_model.decoderlayer_1.blocks.4.norm2.bias', 'model.diffusion_model.decoderlayer_1.blocks.4.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.4.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.4.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.4.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.4.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.4.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.5.norm1.weight', 'model.diffusion_model.decoderlayer_1.blocks.5.norm1.bias', 'model.diffusion_model.decoderlayer_1.blocks.5.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_1.blocks.5.attn.relative_position_index', 'model.diffusion_model.decoderlayer_1.blocks.5.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_1.blocks.5.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_1.blocks.5.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_1.blocks.5.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_1.blocks.5.attn.proj.weight', 'model.diffusion_model.decoderlayer_1.blocks.5.attn.proj.bias', 'model.diffusion_model.decoderlayer_1.blocks.5.norm2.weight', 'model.diffusion_model.decoderlayer_1.blocks.5.norm2.bias', 'model.diffusion_model.decoderlayer_1.blocks.5.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.5.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.5.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.5.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.5.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.5.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.6.norm1.weight', 'model.diffusion_model.decoderlayer_1.blocks.6.norm1.bias', 'model.diffusion_model.decoderlayer_1.blocks.6.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_1.blocks.6.attn.relative_position_index', 'model.diffusion_model.decoderlayer_1.blocks.6.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_1.blocks.6.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_1.blocks.6.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_1.blocks.6.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_1.blocks.6.attn.proj.weight', 'model.diffusion_model.decoderlayer_1.blocks.6.attn.proj.bias', 'model.diffusion_model.decoderlayer_1.blocks.6.norm2.weight', 'model.diffusion_model.decoderlayer_1.blocks.6.norm2.bias', 'model.diffusion_model.decoderlayer_1.blocks.6.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.6.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.6.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.6.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.6.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.6.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.7.norm1.weight', 'model.diffusion_model.decoderlayer_1.blocks.7.norm1.bias', 'model.diffusion_model.decoderlayer_1.blocks.7.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_1.blocks.7.attn.relative_position_index', 'model.diffusion_model.decoderlayer_1.blocks.7.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_1.blocks.7.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_1.blocks.7.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_1.blocks.7.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_1.blocks.7.attn.proj.weight', 'model.diffusion_model.decoderlayer_1.blocks.7.attn.proj.bias', 'model.diffusion_model.decoderlayer_1.blocks.7.norm2.weight', 'model.diffusion_model.decoderlayer_1.blocks.7.norm2.bias', 'model.diffusion_model.decoderlayer_1.blocks.7.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.7.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.7.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.7.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_1.blocks.7.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_1.blocks.7.mlp.linear2.0.bias', 'model.diffusion_model.upsample_2.deconv.0.weight', 'model.diffusion_model.upsample_2.deconv.0.bias', 'model.diffusion_model.decoderlayer_2.time_embed.0.weight', 'model.diffusion_model.decoderlayer_2.time_embed.0.bias', 'model.diffusion_model.decoderlayer_2.time_embed.2.weight', 'model.diffusion_model.decoderlayer_2.time_embed.2.bias', 'model.diffusion_model.decoderlayer_2.blocks.0.norm1.weight', 'model.diffusion_model.decoderlayer_2.blocks.0.norm1.bias', 'model.diffusion_model.decoderlayer_2.blocks.0.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_2.blocks.0.attn.relative_position_index', 'model.diffusion_model.decoderlayer_2.blocks.0.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_2.blocks.0.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_2.blocks.0.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_2.blocks.0.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_2.blocks.0.attn.proj.weight', 'model.diffusion_model.decoderlayer_2.blocks.0.attn.proj.bias', 'model.diffusion_model.decoderlayer_2.blocks.0.norm2.weight', 'model.diffusion_model.decoderlayer_2.blocks.0.norm2.bias', 'model.diffusion_model.decoderlayer_2.blocks.0.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_2.blocks.0.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_2.blocks.0.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_2.blocks.0.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_2.blocks.0.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_2.blocks.0.mlp.linear2.0.bias', 'model.diffusion_model.decoderlayer_2.blocks.1.norm1.weight', 'model.diffusion_model.decoderlayer_2.blocks.1.norm1.bias', 'model.diffusion_model.decoderlayer_2.blocks.1.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_2.blocks.1.attn.relative_position_index', 'model.diffusion_model.decoderlayer_2.blocks.1.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_2.blocks.1.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_2.blocks.1.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_2.blocks.1.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_2.blocks.1.attn.proj.weight', 'model.diffusion_model.decoderlayer_2.blocks.1.attn.proj.bias', 'model.diffusion_model.decoderlayer_2.blocks.1.norm2.weight', 'model.diffusion_model.decoderlayer_2.blocks.1.norm2.bias', 'model.diffusion_model.decoderlayer_2.blocks.1.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_2.blocks.1.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_2.blocks.1.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_2.blocks.1.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_2.blocks.1.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_2.blocks.1.mlp.linear2.0.bias', 'model.diffusion_model.upsample_3.deconv.0.weight', 'model.diffusion_model.upsample_3.deconv.0.bias', 'model.diffusion_model.decoderlayer_3.time_embed.0.weight', 'model.diffusion_model.decoderlayer_3.time_embed.0.bias', 'model.diffusion_model.decoderlayer_3.time_embed.2.weight', 'model.diffusion_model.decoderlayer_3.time_embed.2.bias', 'model.diffusion_model.decoderlayer_3.blocks.0.norm1.weight', 'model.diffusion_model.decoderlayer_3.blocks.0.norm1.bias', 'model.diffusion_model.decoderlayer_3.blocks.0.attn.relative_position_bias_table', 'model.diffusion_model.decoderlayer_3.blocks.0.attn.relative_position_index', 'model.diffusion_model.decoderlayer_3.blocks.0.attn.qkv.to_q.weight', 'model.diffusion_model.decoderlayer_3.blocks.0.attn.qkv.to_q.bias', 'model.diffusion_model.decoderlayer_3.blocks.0.attn.qkv.to_kv.weight', 'model.diffusion_model.decoderlayer_3.blocks.0.attn.qkv.to_kv.bias', 'model.diffusion_model.decoderlayer_3.blocks.0.attn.proj.weight', 'model.diffusion_model.decoderlayer_3.blocks.0.attn.proj.bias', 'model.diffusion_model.decoderlayer_3.blocks.0.norm2.weight', 'model.diffusion_model.decoderlayer_3.blocks.0.norm2.bias', 'model.diffusion_model.decoderlayer_3.blocks.0.mlp.linear1.0.weight', 'model.diffusion_model.decoderlayer_3.blocks.0.mlp.linear1.0.bias', 'model.diffusion_model.decoderlayer_3.blocks.0.mlp.dwconv.0.weight', 'model.diffusion_model.decoderlayer_3.blocks.0.mlp.dwconv.0.bias', 'model.diffusion_model.decoderlayer_3.blocks.0.mlp.linear2.0.weight', 'model.diffusion_model.decoderlayer_3.blocks.0.mlp.linear2.0.bias', 'model_ema.decay', 'model_ema.num_updates', 'model_ema.diffusion_modelinput_projproj0weight', 'model_ema.diffusion_modelinput_projproj0bias', 'model_ema.diffusion_modeloutput_projproj0weight', 'model_ema.diffusion_modeloutput_projproj0bias', 'model_ema.diffusion_modelencoderlayer_0time_embed0weight', 'model_ema.diffusion_modelencoderlayer_0time_embed0bias', 'model_ema.diffusion_modelencoderlayer_0time_embed2weight', 'model_ema.diffusion_modelencoderlayer_0time_embed2bias', 'model_ema.diffusion_modelencoderlayer_0blocks0norm1weight', 'model_ema.diffusion_modelencoderlayer_0blocks0norm1bias', 'model_ema.diffusion_modelencoderlayer_0blocks0attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_0blocks0attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_0blocks0attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_0blocks0attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_0blocks0attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_0blocks0attnprojweight', 'model_ema.diffusion_modelencoderlayer_0blocks0attnprojbias', 'model_ema.diffusion_modelencoderlayer_0blocks0norm2weight', 'model_ema.diffusion_modelencoderlayer_0blocks0norm2bias', 'model_ema.diffusion_modelencoderlayer_0blocks0mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_0blocks0mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_0blocks0mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_0blocks0mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_0blocks0mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_0blocks0mlplinear20bias', 'model_ema.diffusion_modeldowsample_0conv0weight', 'model_ema.diffusion_modeldowsample_0conv0bias', 'model_ema.diffusion_modelencoderlayer_1time_embed0weight', 'model_ema.diffusion_modelencoderlayer_1time_embed0bias', 'model_ema.diffusion_modelencoderlayer_1time_embed2weight', 'model_ema.diffusion_modelencoderlayer_1time_embed2bias', 'model_ema.diffusion_modelencoderlayer_1blocks0norm1weight', 'model_ema.diffusion_modelencoderlayer_1blocks0norm1bias', 'model_ema.diffusion_modelencoderlayer_1blocks0attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_1blocks0attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_1blocks0attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_1blocks0attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_1blocks0attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_1blocks0attnprojweight', 'model_ema.diffusion_modelencoderlayer_1blocks0attnprojbias', 'model_ema.diffusion_modelencoderlayer_1blocks0norm2weight', 'model_ema.diffusion_modelencoderlayer_1blocks0norm2bias', 'model_ema.diffusion_modelencoderlayer_1blocks0mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_1blocks0mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_1blocks0mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_1blocks0mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_1blocks0mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_1blocks0mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_1blocks1norm1weight', 'model_ema.diffusion_modelencoderlayer_1blocks1norm1bias', 'model_ema.diffusion_modelencoderlayer_1blocks1attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_1blocks1attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_1blocks1attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_1blocks1attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_1blocks1attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_1blocks1attnprojweight', 'model_ema.diffusion_modelencoderlayer_1blocks1attnprojbias', 'model_ema.diffusion_modelencoderlayer_1blocks1norm2weight', 'model_ema.diffusion_modelencoderlayer_1blocks1norm2bias', 'model_ema.diffusion_modelencoderlayer_1blocks1mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_1blocks1mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_1blocks1mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_1blocks1mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_1blocks1mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_1blocks1mlplinear20bias', 'model_ema.diffusion_modeldowsample_1conv0weight', 'model_ema.diffusion_modeldowsample_1conv0bias', 'model_ema.diffusion_modelencoderlayer_2time_embed0weight', 'model_ema.diffusion_modelencoderlayer_2time_embed0bias', 'model_ema.diffusion_modelencoderlayer_2time_embed2weight', 'model_ema.diffusion_modelencoderlayer_2time_embed2bias', 'model_ema.diffusion_modelencoderlayer_2blocks0norm1weight', 'model_ema.diffusion_modelencoderlayer_2blocks0norm1bias', 'model_ema.diffusion_modelencoderlayer_2blocks0attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_2blocks0attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_2blocks0attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_2blocks0attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_2blocks0attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_2blocks0attnprojweight', 'model_ema.diffusion_modelencoderlayer_2blocks0attnprojbias', 'model_ema.diffusion_modelencoderlayer_2blocks0norm2weight', 'model_ema.diffusion_modelencoderlayer_2blocks0norm2bias', 'model_ema.diffusion_modelencoderlayer_2blocks0mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_2blocks0mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_2blocks0mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_2blocks0mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_2blocks0mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_2blocks0mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_2blocks1norm1weight', 'model_ema.diffusion_modelencoderlayer_2blocks1norm1bias', 'model_ema.diffusion_modelencoderlayer_2blocks1attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_2blocks1attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_2blocks1attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_2blocks1attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_2blocks1attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_2blocks1attnprojweight', 'model_ema.diffusion_modelencoderlayer_2blocks1attnprojbias', 'model_ema.diffusion_modelencoderlayer_2blocks1norm2weight', 'model_ema.diffusion_modelencoderlayer_2blocks1norm2bias', 'model_ema.diffusion_modelencoderlayer_2blocks1mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_2blocks1mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_2blocks1mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_2blocks1mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_2blocks1mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_2blocks1mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_2blocks2norm1weight', 'model_ema.diffusion_modelencoderlayer_2blocks2norm1bias', 'model_ema.diffusion_modelencoderlayer_2blocks2attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_2blocks2attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_2blocks2attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_2blocks2attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_2blocks2attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_2blocks2attnprojweight', 'model_ema.diffusion_modelencoderlayer_2blocks2attnprojbias', 'model_ema.diffusion_modelencoderlayer_2blocks2norm2weight', 'model_ema.diffusion_modelencoderlayer_2blocks2norm2bias', 'model_ema.diffusion_modelencoderlayer_2blocks2mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_2blocks2mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_2blocks2mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_2blocks2mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_2blocks2mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_2blocks2mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_2blocks3norm1weight', 'model_ema.diffusion_modelencoderlayer_2blocks3norm1bias', 'model_ema.diffusion_modelencoderlayer_2blocks3attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_2blocks3attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_2blocks3attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_2blocks3attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_2blocks3attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_2blocks3attnprojweight', 'model_ema.diffusion_modelencoderlayer_2blocks3attnprojbias', 'model_ema.diffusion_modelencoderlayer_2blocks3norm2weight', 'model_ema.diffusion_modelencoderlayer_2blocks3norm2bias', 'model_ema.diffusion_modelencoderlayer_2blocks3mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_2blocks3mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_2blocks3mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_2blocks3mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_2blocks3mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_2blocks3mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_2blocks4norm1weight', 'model_ema.diffusion_modelencoderlayer_2blocks4norm1bias', 'model_ema.diffusion_modelencoderlayer_2blocks4attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_2blocks4attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_2blocks4attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_2blocks4attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_2blocks4attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_2blocks4attnprojweight', 'model_ema.diffusion_modelencoderlayer_2blocks4attnprojbias', 'model_ema.diffusion_modelencoderlayer_2blocks4norm2weight', 'model_ema.diffusion_modelencoderlayer_2blocks4norm2bias', 'model_ema.diffusion_modelencoderlayer_2blocks4mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_2blocks4mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_2blocks4mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_2blocks4mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_2blocks4mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_2blocks4mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_2blocks5norm1weight', 'model_ema.diffusion_modelencoderlayer_2blocks5norm1bias', 'model_ema.diffusion_modelencoderlayer_2blocks5attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_2blocks5attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_2blocks5attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_2blocks5attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_2blocks5attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_2blocks5attnprojweight', 'model_ema.diffusion_modelencoderlayer_2blocks5attnprojbias', 'model_ema.diffusion_modelencoderlayer_2blocks5norm2weight', 'model_ema.diffusion_modelencoderlayer_2blocks5norm2bias', 'model_ema.diffusion_modelencoderlayer_2blocks5mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_2blocks5mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_2blocks5mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_2blocks5mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_2blocks5mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_2blocks5mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_2blocks6norm1weight', 'model_ema.diffusion_modelencoderlayer_2blocks6norm1bias', 'model_ema.diffusion_modelencoderlayer_2blocks6attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_2blocks6attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_2blocks6attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_2blocks6attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_2blocks6attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_2blocks6attnprojweight', 'model_ema.diffusion_modelencoderlayer_2blocks6attnprojbias', 'model_ema.diffusion_modelencoderlayer_2blocks6norm2weight', 'model_ema.diffusion_modelencoderlayer_2blocks6norm2bias', 'model_ema.diffusion_modelencoderlayer_2blocks6mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_2blocks6mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_2blocks6mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_2blocks6mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_2blocks6mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_2blocks6mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_2blocks7norm1weight', 'model_ema.diffusion_modelencoderlayer_2blocks7norm1bias', 'model_ema.diffusion_modelencoderlayer_2blocks7attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_2blocks7attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_2blocks7attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_2blocks7attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_2blocks7attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_2blocks7attnprojweight', 'model_ema.diffusion_modelencoderlayer_2blocks7attnprojbias', 'model_ema.diffusion_modelencoderlayer_2blocks7norm2weight', 'model_ema.diffusion_modelencoderlayer_2blocks7norm2bias', 'model_ema.diffusion_modelencoderlayer_2blocks7mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_2blocks7mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_2blocks7mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_2blocks7mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_2blocks7mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_2blocks7mlplinear20bias', 'model_ema.diffusion_modeldowsample_2conv0weight', 'model_ema.diffusion_modeldowsample_2conv0bias', 'model_ema.diffusion_modelencoderlayer_3time_embed0weight', 'model_ema.diffusion_modelencoderlayer_3time_embed0bias', 'model_ema.diffusion_modelencoderlayer_3time_embed2weight', 'model_ema.diffusion_modelencoderlayer_3time_embed2bias', 'model_ema.diffusion_modelencoderlayer_3blocks0norm1weight', 'model_ema.diffusion_modelencoderlayer_3blocks0norm1bias', 'model_ema.diffusion_modelencoderlayer_3blocks0attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_3blocks0attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_3blocks0attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_3blocks0attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_3blocks0attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_3blocks0attnprojweight', 'model_ema.diffusion_modelencoderlayer_3blocks0attnprojbias', 'model_ema.diffusion_modelencoderlayer_3blocks0norm2weight', 'model_ema.diffusion_modelencoderlayer_3blocks0norm2bias', 'model_ema.diffusion_modelencoderlayer_3blocks0mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_3blocks0mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_3blocks0mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_3blocks0mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_3blocks0mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_3blocks0mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_3blocks1norm1weight', 'model_ema.diffusion_modelencoderlayer_3blocks1norm1bias', 'model_ema.diffusion_modelencoderlayer_3blocks1attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_3blocks1attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_3blocks1attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_3blocks1attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_3blocks1attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_3blocks1attnprojweight', 'model_ema.diffusion_modelencoderlayer_3blocks1attnprojbias', 'model_ema.diffusion_modelencoderlayer_3blocks1norm2weight', 'model_ema.diffusion_modelencoderlayer_3blocks1norm2bias', 'model_ema.diffusion_modelencoderlayer_3blocks1mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_3blocks1mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_3blocks1mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_3blocks1mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_3blocks1mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_3blocks1mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_3blocks2norm1weight', 'model_ema.diffusion_modelencoderlayer_3blocks2norm1bias', 'model_ema.diffusion_modelencoderlayer_3blocks2attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_3blocks2attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_3blocks2attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_3blocks2attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_3blocks2attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_3blocks2attnprojweight', 'model_ema.diffusion_modelencoderlayer_3blocks2attnprojbias', 'model_ema.diffusion_modelencoderlayer_3blocks2norm2weight', 'model_ema.diffusion_modelencoderlayer_3blocks2norm2bias', 'model_ema.diffusion_modelencoderlayer_3blocks2mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_3blocks2mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_3blocks2mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_3blocks2mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_3blocks2mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_3blocks2mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_3blocks3norm1weight', 'model_ema.diffusion_modelencoderlayer_3blocks3norm1bias', 'model_ema.diffusion_modelencoderlayer_3blocks3attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_3blocks3attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_3blocks3attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_3blocks3attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_3blocks3attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_3blocks3attnprojweight', 'model_ema.diffusion_modelencoderlayer_3blocks3attnprojbias', 'model_ema.diffusion_modelencoderlayer_3blocks3norm2weight', 'model_ema.diffusion_modelencoderlayer_3blocks3norm2bias', 'model_ema.diffusion_modelencoderlayer_3blocks3mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_3blocks3mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_3blocks3mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_3blocks3mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_3blocks3mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_3blocks3mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_3blocks4norm1weight', 'model_ema.diffusion_modelencoderlayer_3blocks4norm1bias', 'model_ema.diffusion_modelencoderlayer_3blocks4attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_3blocks4attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_3blocks4attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_3blocks4attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_3blocks4attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_3blocks4attnprojweight', 'model_ema.diffusion_modelencoderlayer_3blocks4attnprojbias', 'model_ema.diffusion_modelencoderlayer_3blocks4norm2weight', 'model_ema.diffusion_modelencoderlayer_3blocks4norm2bias', 'model_ema.diffusion_modelencoderlayer_3blocks4mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_3blocks4mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_3blocks4mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_3blocks4mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_3blocks4mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_3blocks4mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_3blocks5norm1weight', 'model_ema.diffusion_modelencoderlayer_3blocks5norm1bias', 'model_ema.diffusion_modelencoderlayer_3blocks5attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_3blocks5attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_3blocks5attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_3blocks5attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_3blocks5attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_3blocks5attnprojweight', 'model_ema.diffusion_modelencoderlayer_3blocks5attnprojbias', 'model_ema.diffusion_modelencoderlayer_3blocks5norm2weight', 'model_ema.diffusion_modelencoderlayer_3blocks5norm2bias', 'model_ema.diffusion_modelencoderlayer_3blocks5mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_3blocks5mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_3blocks5mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_3blocks5mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_3blocks5mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_3blocks5mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_3blocks6norm1weight', 'model_ema.diffusion_modelencoderlayer_3blocks6norm1bias', 'model_ema.diffusion_modelencoderlayer_3blocks6attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_3blocks6attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_3blocks6attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_3blocks6attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_3blocks6attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_3blocks6attnprojweight', 'model_ema.diffusion_modelencoderlayer_3blocks6attnprojbias', 'model_ema.diffusion_modelencoderlayer_3blocks6norm2weight', 'model_ema.diffusion_modelencoderlayer_3blocks6norm2bias', 'model_ema.diffusion_modelencoderlayer_3blocks6mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_3blocks6mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_3blocks6mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_3blocks6mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_3blocks6mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_3blocks6mlplinear20bias', 'model_ema.diffusion_modelencoderlayer_3blocks7norm1weight', 'model_ema.diffusion_modelencoderlayer_3blocks7norm1bias', 'model_ema.diffusion_modelencoderlayer_3blocks7attnrelative_position_bias_table', 'model_ema.diffusion_modelencoderlayer_3blocks7attnqkvto_qweight', 'model_ema.diffusion_modelencoderlayer_3blocks7attnqkvto_qbias', 'model_ema.diffusion_modelencoderlayer_3blocks7attnqkvto_kvweight', 'model_ema.diffusion_modelencoderlayer_3blocks7attnqkvto_kvbias', 'model_ema.diffusion_modelencoderlayer_3blocks7attnprojweight', 'model_ema.diffusion_modelencoderlayer_3blocks7attnprojbias', 'model_ema.diffusion_modelencoderlayer_3blocks7norm2weight', 'model_ema.diffusion_modelencoderlayer_3blocks7norm2bias', 'model_ema.diffusion_modelencoderlayer_3blocks7mlplinear10weight', 'model_ema.diffusion_modelencoderlayer_3blocks7mlplinear10bias', 'model_ema.diffusion_modelencoderlayer_3blocks7mlpdwconv0weight', 'model_ema.diffusion_modelencoderlayer_3blocks7mlpdwconv0bias', 'model_ema.diffusion_modelencoderlayer_3blocks7mlplinear20weight', 'model_ema.diffusion_modelencoderlayer_3blocks7mlplinear20bias', 'model_ema.diffusion_modeldowsample_3conv0weight', 'model_ema.diffusion_modeldowsample_3conv0bias', 'model_ema.diffusion_modelconvtime_embed0weight', 'model_ema.diffusion_modelconvtime_embed0bias', 'model_ema.diffusion_modelconvtime_embed2weight', 'model_ema.diffusion_modelconvtime_embed2bias', 'model_ema.diffusion_modelconvblocks0norm1weight', 'model_ema.diffusion_modelconvblocks0norm1bias', 'model_ema.diffusion_modelconvblocks0attnrelative_position_bias_table', 'model_ema.diffusion_modelconvblocks0attnqkvto_qweight', 'model_ema.diffusion_modelconvblocks0attnqkvto_qbias', 'model_ema.diffusion_modelconvblocks0attnqkvto_kvweight', 'model_ema.diffusion_modelconvblocks0attnqkvto_kvbias', 'model_ema.diffusion_modelconvblocks0attnprojweight', 'model_ema.diffusion_modelconvblocks0attnprojbias', 'model_ema.diffusion_modelconvblocks0norm2weight', 'model_ema.diffusion_modelconvblocks0norm2bias', 'model_ema.diffusion_modelconvblocks0mlplinear10weight', 'model_ema.diffusion_modelconvblocks0mlplinear10bias', 'model_ema.diffusion_modelconvblocks0mlpdwconv0weight', 'model_ema.diffusion_modelconvblocks0mlpdwconv0bias', 'model_ema.diffusion_modelconvblocks0mlplinear20weight', 'model_ema.diffusion_modelconvblocks0mlplinear20bias', 'model_ema.diffusion_modelconvblocks1norm1weight', 'model_ema.diffusion_modelconvblocks1norm1bias', 'model_ema.diffusion_modelconvblocks1attnrelative_position_bias_table', 'model_ema.diffusion_modelconvblocks1attnqkvto_qweight', 'model_ema.diffusion_modelconvblocks1attnqkvto_qbias', 'model_ema.diffusion_modelconvblocks1attnqkvto_kvweight', 'model_ema.diffusion_modelconvblocks1attnqkvto_kvbias', 'model_ema.diffusion_modelconvblocks1attnprojweight', 'model_ema.diffusion_modelconvblocks1attnprojbias', 'model_ema.diffusion_modelconvblocks1norm2weight', 'model_ema.diffusion_modelconvblocks1norm2bias', 'model_ema.diffusion_modelconvblocks1mlplinear10weight', 'model_ema.diffusion_modelconvblocks1mlplinear10bias', 'model_ema.diffusion_modelconvblocks1mlpdwconv0weight', 'model_ema.diffusion_modelconvblocks1mlpdwconv0bias', 'model_ema.diffusion_modelconvblocks1mlplinear20weight', 'model_ema.diffusion_modelconvblocks1mlplinear20bias', 'model_ema.diffusion_modelupsample_0deconv0weight', 'model_ema.diffusion_modelupsample_0deconv0bias', 'model_ema.diffusion_modeldecoderlayer_0time_embed0weight', 'model_ema.diffusion_modeldecoderlayer_0time_embed0bias', 'model_ema.diffusion_modeldecoderlayer_0time_embed2weight', 'model_ema.diffusion_modeldecoderlayer_0time_embed2bias', 'model_ema.diffusion_modeldecoderlayer_0blocks0norm1weight', 'model_ema.diffusion_modeldecoderlayer_0blocks0norm1bias', 'model_ema.diffusion_modeldecoderlayer_0blocks0attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_0blocks0attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_0blocks0attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_0blocks0attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_0blocks0attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_0blocks0attnprojweight', 'model_ema.diffusion_modeldecoderlayer_0blocks0attnprojbias', 'model_ema.diffusion_modeldecoderlayer_0blocks0norm2weight', 'model_ema.diffusion_modeldecoderlayer_0blocks0norm2bias', 'model_ema.diffusion_modeldecoderlayer_0blocks0mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_0blocks0mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_0blocks0mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_0blocks0mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_0blocks0mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_0blocks0mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_0blocks1norm1weight', 'model_ema.diffusion_modeldecoderlayer_0blocks1norm1bias', 'model_ema.diffusion_modeldecoderlayer_0blocks1attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_0blocks1attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_0blocks1attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_0blocks1attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_0blocks1attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_0blocks1attnprojweight', 'model_ema.diffusion_modeldecoderlayer_0blocks1attnprojbias', 'model_ema.diffusion_modeldecoderlayer_0blocks1norm2weight', 'model_ema.diffusion_modeldecoderlayer_0blocks1norm2bias', 'model_ema.diffusion_modeldecoderlayer_0blocks1mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_0blocks1mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_0blocks1mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_0blocks1mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_0blocks1mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_0blocks1mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_0blocks2norm1weight', 'model_ema.diffusion_modeldecoderlayer_0blocks2norm1bias', 'model_ema.diffusion_modeldecoderlayer_0blocks2attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_0blocks2attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_0blocks2attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_0blocks2attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_0blocks2attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_0blocks2attnprojweight', 'model_ema.diffusion_modeldecoderlayer_0blocks2attnprojbias', 'model_ema.diffusion_modeldecoderlayer_0blocks2norm2weight', 'model_ema.diffusion_modeldecoderlayer_0blocks2norm2bias', 'model_ema.diffusion_modeldecoderlayer_0blocks2mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_0blocks2mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_0blocks2mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_0blocks2mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_0blocks2mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_0blocks2mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_0blocks3norm1weight', 'model_ema.diffusion_modeldecoderlayer_0blocks3norm1bias', 'model_ema.diffusion_modeldecoderlayer_0blocks3attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_0blocks3attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_0blocks3attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_0blocks3attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_0blocks3attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_0blocks3attnprojweight', 'model_ema.diffusion_modeldecoderlayer_0blocks3attnprojbias', 'model_ema.diffusion_modeldecoderlayer_0blocks3norm2weight', 'model_ema.diffusion_modeldecoderlayer_0blocks3norm2bias', 'model_ema.diffusion_modeldecoderlayer_0blocks3mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_0blocks3mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_0blocks3mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_0blocks3mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_0blocks3mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_0blocks3mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_0blocks4norm1weight', 'model_ema.diffusion_modeldecoderlayer_0blocks4norm1bias', 'model_ema.diffusion_modeldecoderlayer_0blocks4attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_0blocks4attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_0blocks4attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_0blocks4attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_0blocks4attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_0blocks4attnprojweight', 'model_ema.diffusion_modeldecoderlayer_0blocks4attnprojbias', 'model_ema.diffusion_modeldecoderlayer_0blocks4norm2weight', 'model_ema.diffusion_modeldecoderlayer_0blocks4norm2bias', 'model_ema.diffusion_modeldecoderlayer_0blocks4mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_0blocks4mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_0blocks4mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_0blocks4mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_0blocks4mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_0blocks4mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_0blocks5norm1weight', 'model_ema.diffusion_modeldecoderlayer_0blocks5norm1bias', 'model_ema.diffusion_modeldecoderlayer_0blocks5attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_0blocks5attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_0blocks5attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_0blocks5attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_0blocks5attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_0blocks5attnprojweight', 'model_ema.diffusion_modeldecoderlayer_0blocks5attnprojbias', 'model_ema.diffusion_modeldecoderlayer_0blocks5norm2weight', 'model_ema.diffusion_modeldecoderlayer_0blocks5norm2bias', 'model_ema.diffusion_modeldecoderlayer_0blocks5mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_0blocks5mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_0blocks5mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_0blocks5mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_0blocks5mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_0blocks5mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_0blocks6norm1weight', 'model_ema.diffusion_modeldecoderlayer_0blocks6norm1bias', 'model_ema.diffusion_modeldecoderlayer_0blocks6attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_0blocks6attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_0blocks6attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_0blocks6attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_0blocks6attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_0blocks6attnprojweight', 'model_ema.diffusion_modeldecoderlayer_0blocks6attnprojbias', 'model_ema.diffusion_modeldecoderlayer_0blocks6norm2weight', 'model_ema.diffusion_modeldecoderlayer_0blocks6norm2bias', 'model_ema.diffusion_modeldecoderlayer_0blocks6mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_0blocks6mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_0blocks6mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_0blocks6mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_0blocks6mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_0blocks6mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_0blocks7norm1weight', 'model_ema.diffusion_modeldecoderlayer_0blocks7norm1bias', 'model_ema.diffusion_modeldecoderlayer_0blocks7attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_0blocks7attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_0blocks7attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_0blocks7attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_0blocks7attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_0blocks7attnprojweight', 'model_ema.diffusion_modeldecoderlayer_0blocks7attnprojbias', 'model_ema.diffusion_modeldecoderlayer_0blocks7norm2weight', 'model_ema.diffusion_modeldecoderlayer_0blocks7norm2bias', 'model_ema.diffusion_modeldecoderlayer_0blocks7mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_0blocks7mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_0blocks7mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_0blocks7mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_0blocks7mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_0blocks7mlplinear20bias', 'model_ema.diffusion_modelupsample_1deconv0weight', 'model_ema.diffusion_modelupsample_1deconv0bias', 'model_ema.diffusion_modeldecoderlayer_1time_embed0weight', 'model_ema.diffusion_modeldecoderlayer_1time_embed0bias', 'model_ema.diffusion_modeldecoderlayer_1time_embed2weight', 'model_ema.diffusion_modeldecoderlayer_1time_embed2bias', 'model_ema.diffusion_modeldecoderlayer_1blocks0norm1weight', 'model_ema.diffusion_modeldecoderlayer_1blocks0norm1bias', 'model_ema.diffusion_modeldecoderlayer_1blocks0attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_1blocks0attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_1blocks0attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_1blocks0attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_1blocks0attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_1blocks0attnprojweight', 'model_ema.diffusion_modeldecoderlayer_1blocks0attnprojbias', 'model_ema.diffusion_modeldecoderlayer_1blocks0norm2weight', 'model_ema.diffusion_modeldecoderlayer_1blocks0norm2bias', 'model_ema.diffusion_modeldecoderlayer_1blocks0mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_1blocks0mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_1blocks0mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_1blocks0mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_1blocks0mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_1blocks0mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_1blocks1norm1weight', 'model_ema.diffusion_modeldecoderlayer_1blocks1norm1bias', 'model_ema.diffusion_modeldecoderlayer_1blocks1attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_1blocks1attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_1blocks1attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_1blocks1attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_1blocks1attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_1blocks1attnprojweight', 'model_ema.diffusion_modeldecoderlayer_1blocks1attnprojbias', 'model_ema.diffusion_modeldecoderlayer_1blocks1norm2weight', 'model_ema.diffusion_modeldecoderlayer_1blocks1norm2bias', 'model_ema.diffusion_modeldecoderlayer_1blocks1mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_1blocks1mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_1blocks1mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_1blocks1mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_1blocks1mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_1blocks1mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_1blocks2norm1weight', 'model_ema.diffusion_modeldecoderlayer_1blocks2norm1bias', 'model_ema.diffusion_modeldecoderlayer_1blocks2attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_1blocks2attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_1blocks2attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_1blocks2attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_1blocks2attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_1blocks2attnprojweight', 'model_ema.diffusion_modeldecoderlayer_1blocks2attnprojbias', 'model_ema.diffusion_modeldecoderlayer_1blocks2norm2weight', 'model_ema.diffusion_modeldecoderlayer_1blocks2norm2bias', 'model_ema.diffusion_modeldecoderlayer_1blocks2mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_1blocks2mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_1blocks2mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_1blocks2mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_1blocks2mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_1blocks2mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_1blocks3norm1weight', 'model_ema.diffusion_modeldecoderlayer_1blocks3norm1bias', 'model_ema.diffusion_modeldecoderlayer_1blocks3attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_1blocks3attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_1blocks3attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_1blocks3attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_1blocks3attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_1blocks3attnprojweight', 'model_ema.diffusion_modeldecoderlayer_1blocks3attnprojbias', 'model_ema.diffusion_modeldecoderlayer_1blocks3norm2weight', 'model_ema.diffusion_modeldecoderlayer_1blocks3norm2bias', 'model_ema.diffusion_modeldecoderlayer_1blocks3mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_1blocks3mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_1blocks3mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_1blocks3mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_1blocks3mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_1blocks3mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_1blocks4norm1weight', 'model_ema.diffusion_modeldecoderlayer_1blocks4norm1bias', 'model_ema.diffusion_modeldecoderlayer_1blocks4attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_1blocks4attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_1blocks4attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_1blocks4attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_1blocks4attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_1blocks4attnprojweight', 'model_ema.diffusion_modeldecoderlayer_1blocks4attnprojbias', 'model_ema.diffusion_modeldecoderlayer_1blocks4norm2weight', 'model_ema.diffusion_modeldecoderlayer_1blocks4norm2bias', 'model_ema.diffusion_modeldecoderlayer_1blocks4mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_1blocks4mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_1blocks4mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_1blocks4mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_1blocks4mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_1blocks4mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_1blocks5norm1weight', 'model_ema.diffusion_modeldecoderlayer_1blocks5norm1bias', 'model_ema.diffusion_modeldecoderlayer_1blocks5attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_1blocks5attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_1blocks5attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_1blocks5attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_1blocks5attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_1blocks5attnprojweight', 'model_ema.diffusion_modeldecoderlayer_1blocks5attnprojbias', 'model_ema.diffusion_modeldecoderlayer_1blocks5norm2weight', 'model_ema.diffusion_modeldecoderlayer_1blocks5norm2bias', 'model_ema.diffusion_modeldecoderlayer_1blocks5mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_1blocks5mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_1blocks5mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_1blocks5mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_1blocks5mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_1blocks5mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_1blocks6norm1weight', 'model_ema.diffusion_modeldecoderlayer_1blocks6norm1bias', 'model_ema.diffusion_modeldecoderlayer_1blocks6attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_1blocks6attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_1blocks6attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_1blocks6attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_1blocks6attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_1blocks6attnprojweight', 'model_ema.diffusion_modeldecoderlayer_1blocks6attnprojbias', 'model_ema.diffusion_modeldecoderlayer_1blocks6norm2weight', 'model_ema.diffusion_modeldecoderlayer_1blocks6norm2bias', 'model_ema.diffusion_modeldecoderlayer_1blocks6mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_1blocks6mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_1blocks6mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_1blocks6mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_1blocks6mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_1blocks6mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_1blocks7norm1weight', 'model_ema.diffusion_modeldecoderlayer_1blocks7norm1bias', 'model_ema.diffusion_modeldecoderlayer_1blocks7attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_1blocks7attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_1blocks7attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_1blocks7attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_1blocks7attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_1blocks7attnprojweight', 'model_ema.diffusion_modeldecoderlayer_1blocks7attnprojbias', 'model_ema.diffusion_modeldecoderlayer_1blocks7norm2weight', 'model_ema.diffusion_modeldecoderlayer_1blocks7norm2bias', 'model_ema.diffusion_modeldecoderlayer_1blocks7mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_1blocks7mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_1blocks7mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_1blocks7mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_1blocks7mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_1blocks7mlplinear20bias', 'model_ema.diffusion_modelupsample_2deconv0weight', 'model_ema.diffusion_modelupsample_2deconv0bias', 'model_ema.diffusion_modeldecoderlayer_2time_embed0weight', 'model_ema.diffusion_modeldecoderlayer_2time_embed0bias', 'model_ema.diffusion_modeldecoderlayer_2time_embed2weight', 'model_ema.diffusion_modeldecoderlayer_2time_embed2bias', 'model_ema.diffusion_modeldecoderlayer_2blocks0norm1weight', 'model_ema.diffusion_modeldecoderlayer_2blocks0norm1bias', 'model_ema.diffusion_modeldecoderlayer_2blocks0attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_2blocks0attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_2blocks0attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_2blocks0attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_2blocks0attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_2blocks0attnprojweight', 'model_ema.diffusion_modeldecoderlayer_2blocks0attnprojbias', 'model_ema.diffusion_modeldecoderlayer_2blocks0norm2weight', 'model_ema.diffusion_modeldecoderlayer_2blocks0norm2bias', 'model_ema.diffusion_modeldecoderlayer_2blocks0mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_2blocks0mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_2blocks0mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_2blocks0mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_2blocks0mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_2blocks0mlplinear20bias', 'model_ema.diffusion_modeldecoderlayer_2blocks1norm1weight', 'model_ema.diffusion_modeldecoderlayer_2blocks1norm1bias', 'model_ema.diffusion_modeldecoderlayer_2blocks1attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_2blocks1attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_2blocks1attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_2blocks1attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_2blocks1attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_2blocks1attnprojweight', 'model_ema.diffusion_modeldecoderlayer_2blocks1attnprojbias', 'model_ema.diffusion_modeldecoderlayer_2blocks1norm2weight', 'model_ema.diffusion_modeldecoderlayer_2blocks1norm2bias', 'model_ema.diffusion_modeldecoderlayer_2blocks1mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_2blocks1mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_2blocks1mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_2blocks1mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_2blocks1mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_2blocks1mlplinear20bias', 'model_ema.diffusion_modelupsample_3deconv0weight', 'model_ema.diffusion_modelupsample_3deconv0bias', 'model_ema.diffusion_modeldecoderlayer_3time_embed0weight', 'model_ema.diffusion_modeldecoderlayer_3time_embed0bias', 'model_ema.diffusion_modeldecoderlayer_3time_embed2weight', 'model_ema.diffusion_modeldecoderlayer_3time_embed2bias', 'model_ema.diffusion_modeldecoderlayer_3blocks0norm1weight', 'model_ema.diffusion_modeldecoderlayer_3blocks0norm1bias', 'model_ema.diffusion_modeldecoderlayer_3blocks0attnrelative_position_bias_table', 'model_ema.diffusion_modeldecoderlayer_3blocks0attnqkvto_qweight', 'model_ema.diffusion_modeldecoderlayer_3blocks0attnqkvto_qbias', 'model_ema.diffusion_modeldecoderlayer_3blocks0attnqkvto_kvweight', 'model_ema.diffusion_modeldecoderlayer_3blocks0attnqkvto_kvbias', 'model_ema.diffusion_modeldecoderlayer_3blocks0attnprojweight', 'model_ema.diffusion_modeldecoderlayer_3blocks0attnprojbias', 'model_ema.diffusion_modeldecoderlayer_3blocks0norm2weight', 'model_ema.diffusion_modeldecoderlayer_3blocks0norm2bias', 'model_ema.diffusion_modeldecoderlayer_3blocks0mlplinear10weight', 'model_ema.diffusion_modeldecoderlayer_3blocks0mlplinear10bias', 'model_ema.diffusion_modeldecoderlayer_3blocks0mlpdwconv0weight', 'model_ema.diffusion_modeldecoderlayer_3blocks0mlpdwconv0bias', 'model_ema.diffusion_modeldecoderlayer_3blocks0mlplinear20weight', 'model_ema.diffusion_modeldecoderlayer_3blocks0mlplinear20bias', 'first_stage_model.encoder.conv_in.weight', 'first_stage_model.encoder.conv_in.bias', 'first_stage_model.encoder.down.0.block.0.norm1.weight', 'first_stage_model.encoder.down.0.block.0.norm1.bias', 'first_stage_model.encoder.down.0.block.0.conv1.weight', 'first_stage_model.encoder.down.0.block.0.conv1.bias', 'first_stage_model.encoder.down.0.block.0.norm2.weight', 'first_stage_model.encoder.down.0.block.0.norm2.bias', 'first_stage_model.encoder.down.0.block.0.conv2.weight', 'first_stage_model.encoder.down.0.block.0.conv2.bias', 'first_stage_model.encoder.down.0.block.1.norm1.weight', 'first_stage_model.encoder.down.0.block.1.norm1.bias', 'first_stage_model.encoder.down.0.block.1.conv1.weight', 'first_stage_model.encoder.down.0.block.1.conv1.bias', 'first_stage_model.encoder.down.0.block.1.norm2.weight', 'first_stage_model.encoder.down.0.block.1.norm2.bias', 'first_stage_model.encoder.down.0.block.1.conv2.weight', 'first_stage_model.encoder.down.0.block.1.conv2.bias', 'first_stage_model.encoder.down.0.downsample.conv.weight', 'first_stage_model.encoder.down.0.downsample.conv.bias', 'first_stage_model.encoder.down.1.block.0.norm1.weight', 'first_stage_model.encoder.down.1.block.0.norm1.bias', 'first_stage_model.encoder.down.1.block.0.conv1.weight', 'first_stage_model.encoder.down.1.block.0.conv1.bias', 'first_stage_model.encoder.down.1.block.0.norm2.weight', 'first_stage_model.encoder.down.1.block.0.norm2.bias', 'first_stage_model.encoder.down.1.block.0.conv2.weight', 'first_stage_model.encoder.down.1.block.0.conv2.bias', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.1.block.1.norm1.weight', 'first_stage_model.encoder.down.1.block.1.norm1.bias', 'first_stage_model.encoder.down.1.block.1.conv1.weight', 'first_stage_model.encoder.down.1.block.1.conv1.bias', 'first_stage_model.encoder.down.1.block.1.norm2.weight', 'first_stage_model.encoder.down.1.block.1.norm2.bias', 'first_stage_model.encoder.down.1.block.1.conv2.weight', 'first_stage_model.encoder.down.1.block.1.conv2.bias', 'first_stage_model.encoder.down.1.downsample.conv.weight', 'first_stage_model.encoder.down.1.downsample.conv.bias', 'first_stage_model.encoder.down.2.block.0.norm1.weight', 'first_stage_model.encoder.down.2.block.0.norm1.bias', 'first_stage_model.encoder.down.2.block.0.conv1.weight', 'first_stage_model.encoder.down.2.block.0.conv1.bias', 'first_stage_model.encoder.down.2.block.0.norm2.weight', 'first_stage_model.encoder.down.2.block.0.norm2.bias', 'first_stage_model.encoder.down.2.block.0.conv2.weight', 'first_stage_model.encoder.down.2.block.0.conv2.bias', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.2.block.1.norm1.weight', 'first_stage_model.encoder.down.2.block.1.norm1.bias', 'first_stage_model.encoder.down.2.block.1.conv1.weight', 'first_stage_model.encoder.down.2.block.1.conv1.bias', 'first_stage_model.encoder.down.2.block.1.norm2.weight', 'first_stage_model.encoder.down.2.block.1.norm2.bias', 'first_stage_model.encoder.down.2.block.1.conv2.weight', 'first_stage_model.encoder.down.2.block.1.conv2.bias', 'first_stage_model.encoder.down.2.downsample.conv.weight', 'first_stage_model.encoder.down.2.downsample.conv.bias', 'first_stage_model.encoder.down.3.block.0.norm1.weight', 'first_stage_model.encoder.down.3.block.0.norm1.bias', 'first_stage_model.encoder.down.3.block.0.conv1.weight', 'first_stage_model.encoder.down.3.block.0.conv1.bias', 'first_stage_model.encoder.down.3.block.0.norm2.weight', 'first_stage_model.encoder.down.3.block.0.norm2.bias', 'first_stage_model.encoder.down.3.block.0.conv2.weight', 'first_stage_model.encoder.down.3.block.0.conv2.bias', 'first_stage_model.encoder.down.3.block.1.norm1.weight', 'first_stage_model.encoder.down.3.block.1.norm1.bias', 'first_stage_model.encoder.down.3.block.1.conv1.weight', 'first_stage_model.encoder.down.3.block.1.conv1.bias', 'first_stage_model.encoder.down.3.block.1.norm2.weight', 'first_stage_model.encoder.down.3.block.1.norm2.bias', 'first_stage_model.encoder.down.3.block.1.conv2.weight', 'first_stage_model.encoder.down.3.block.1.conv2.bias', 'first_stage_model.encoder.mid.block_1.norm1.weight', 'first_stage_model.encoder.mid.block_1.norm1.bias', 'first_stage_model.encoder.mid.block_1.conv1.weight', 'first_stage_model.encoder.mid.block_1.conv1.bias', 'first_stage_model.encoder.mid.block_1.norm2.weight', 'first_stage_model.encoder.mid.block_1.norm2.bias', 'first_stage_model.encoder.mid.block_1.conv2.weight', 'first_stage_model.encoder.mid.block_1.conv2.bias', 'first_stage_model.encoder.mid.attn_1.norm.weight', 'first_stage_model.encoder.mid.attn_1.norm.bias', 'first_stage_model.encoder.mid.attn_1.q.weight', 'first_stage_model.encoder.mid.attn_1.q.bias', 'first_stage_model.encoder.mid.attn_1.k.weight', 'first_stage_model.encoder.mid.attn_1.k.bias', 'first_stage_model.encoder.mid.attn_1.v.weight', 'first_stage_model.encoder.mid.attn_1.v.bias', 'first_stage_model.encoder.mid.attn_1.proj_out.weight', 'first_stage_model.encoder.mid.attn_1.proj_out.bias', 'first_stage_model.encoder.mid.block_2.norm1.weight', 'first_stage_model.encoder.mid.block_2.norm1.bias', 'first_stage_model.encoder.mid.block_2.conv1.weight', 'first_stage_model.encoder.mid.block_2.conv1.bias', 'first_stage_model.encoder.mid.block_2.norm2.weight', 'first_stage_model.encoder.mid.block_2.norm2.bias', 'first_stage_model.encoder.mid.block_2.conv2.weight', 'first_stage_model.encoder.mid.block_2.conv2.bias', 'first_stage_model.encoder.norm_out.weight', 'first_stage_model.encoder.norm_out.bias', 'first_stage_model.encoder.conv_out.weight', 'first_stage_model.encoder.conv_out.bias', 'first_stage_model.decoder.conv_in.weight', 'first_stage_model.decoder.conv_in.bias', 'first_stage_model.decoder.mid.block_1.norm1.weight', 'first_stage_model.decoder.mid.block_1.norm1.bias', 'first_stage_model.decoder.mid.block_1.conv1.weight', 'first_stage_model.decoder.mid.block_1.conv1.bias', 'first_stage_model.decoder.mid.block_1.norm2.weight', 'first_stage_model.decoder.mid.block_1.norm2.bias', 'first_stage_model.decoder.mid.block_1.conv2.weight', 'first_stage_model.decoder.mid.block_1.conv2.bias', 'first_stage_model.decoder.mid.attn_1.norm.weight', 'first_stage_model.decoder.mid.attn_1.norm.bias', 'first_stage_model.decoder.mid.attn_1.q.weight', 'first_stage_model.decoder.mid.attn_1.q.bias', 'first_stage_model.decoder.mid.attn_1.k.weight', 'first_stage_model.decoder.mid.attn_1.k.bias', 'first_stage_model.decoder.mid.attn_1.v.weight', 'first_stage_model.decoder.mid.attn_1.v.bias', 'first_stage_model.decoder.mid.attn_1.proj_out.weight', 'first_stage_model.decoder.mid.attn_1.proj_out.bias', 'first_stage_model.decoder.mid.block_2.norm1.weight', 'first_stage_model.decoder.mid.block_2.norm1.bias', 'first_stage_model.decoder.mid.block_2.conv1.weight', 'first_stage_model.decoder.mid.block_2.conv1.bias', 'first_stage_model.decoder.mid.block_2.norm2.weight', 'first_stage_model.decoder.mid.block_2.norm2.bias', 'first_stage_model.decoder.mid.block_2.conv2.weight', 'first_stage_model.decoder.mid.block_2.conv2.bias', 'first_stage_model.decoder.up.0.block.0.norm1.weight', 'first_stage_model.decoder.up.0.block.0.norm1.bias', 'first_stage_model.decoder.up.0.block.0.conv1.weight', 'first_stage_model.decoder.up.0.block.0.conv1.bias', 'first_stage_model.decoder.up.0.block.0.norm2.weight', 'first_stage_model.decoder.up.0.block.0.norm2.bias', 'first_stage_model.decoder.up.0.block.0.conv2.weight', 'first_stage_model.decoder.up.0.block.0.conv2.bias', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.0.block.1.norm1.weight', 'first_stage_model.decoder.up.0.block.1.norm1.bias', 'first_stage_model.decoder.up.0.block.1.conv1.weight', 'first_stage_model.decoder.up.0.block.1.conv1.bias', 'first_stage_model.decoder.up.0.block.1.norm2.weight', 'first_stage_model.decoder.up.0.block.1.norm2.bias', 'first_stage_model.decoder.up.0.block.1.conv2.weight', 'first_stage_model.decoder.up.0.block.1.conv2.bias', 'first_stage_model.decoder.up.0.block.2.norm1.weight', 'first_stage_model.decoder.up.0.block.2.norm1.bias', 'first_stage_model.decoder.up.0.block.2.conv1.weight', 'first_stage_model.decoder.up.0.block.2.conv1.bias', 'first_stage_model.decoder.up.0.block.2.norm2.weight', 'first_stage_model.decoder.up.0.block.2.norm2.bias', 'first_stage_model.decoder.up.0.block.2.conv2.weight', 'first_stage_model.decoder.up.0.block.2.conv2.bias', 'first_stage_model.decoder.up.1.block.0.norm1.weight', 'first_stage_model.decoder.up.1.block.0.norm1.bias', 'first_stage_model.decoder.up.1.block.0.conv1.weight', 'first_stage_model.decoder.up.1.block.0.conv1.bias', 'first_stage_model.decoder.up.1.block.0.norm2.weight', 'first_stage_model.decoder.up.1.block.0.norm2.bias', 'first_stage_model.decoder.up.1.block.0.conv2.weight', 'first_stage_model.decoder.up.1.block.0.conv2.bias', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.1.block.1.norm1.weight', 'first_stage_model.decoder.up.1.block.1.norm1.bias', 'first_stage_model.decoder.up.1.block.1.conv1.weight', 'first_stage_model.decoder.up.1.block.1.conv1.bias', 'first_stage_model.decoder.up.1.block.1.norm2.weight', 'first_stage_model.decoder.up.1.block.1.norm2.bias', 'first_stage_model.decoder.up.1.block.1.conv2.weight', 'first_stage_model.decoder.up.1.block.1.conv2.bias', 'first_stage_model.decoder.up.1.block.2.norm1.weight', 'first_stage_model.decoder.up.1.block.2.norm1.bias', 'first_stage_model.decoder.up.1.block.2.conv1.weight', 'first_stage_model.decoder.up.1.block.2.conv1.bias', 'first_stage_model.decoder.up.1.block.2.norm2.weight', 'first_stage_model.decoder.up.1.block.2.norm2.bias', 'first_stage_model.decoder.up.1.block.2.conv2.weight', 'first_stage_model.decoder.up.1.block.2.conv2.bias', 'first_stage_model.decoder.up.1.upsample.conv.weight', 'first_stage_model.decoder.up.1.upsample.conv.bias', 'first_stage_model.decoder.up.2.block.0.norm1.weight', 'first_stage_model.decoder.up.2.block.0.norm1.bias', 'first_stage_model.decoder.up.2.block.0.conv1.weight', 'first_stage_model.decoder.up.2.block.0.conv1.bias', 'first_stage_model.decoder.up.2.block.0.norm2.weight', 'first_stage_model.decoder.up.2.block.0.norm2.bias', 'first_stage_model.decoder.up.2.block.0.conv2.weight', 'first_stage_model.decoder.up.2.block.0.conv2.bias', 'first_stage_model.decoder.up.2.block.1.norm1.weight', 'first_stage_model.decoder.up.2.block.1.norm1.bias', 'first_stage_model.decoder.up.2.block.1.conv1.weight', 'first_stage_model.decoder.up.2.block.1.conv1.bias', 'first_stage_model.decoder.up.2.block.1.norm2.weight', 'first_stage_model.decoder.up.2.block.1.norm2.bias', 'first_stage_model.decoder.up.2.block.1.conv2.weight', 'first_stage_model.decoder.up.2.block.1.conv2.bias', 'first_stage_model.decoder.up.2.block.2.norm1.weight', 'first_stage_model.decoder.up.2.block.2.norm1.bias', 'first_stage_model.decoder.up.2.block.2.conv1.weight', 'first_stage_model.decoder.up.2.block.2.conv1.bias', 'first_stage_model.decoder.up.2.block.2.norm2.weight', 'first_stage_model.decoder.up.2.block.2.norm2.bias', 'first_stage_model.decoder.up.2.block.2.conv2.weight', 'first_stage_model.decoder.up.2.block.2.conv2.bias', 'first_stage_model.decoder.up.2.upsample.conv.weight', 'first_stage_model.decoder.up.2.upsample.conv.bias', 'first_stage_model.decoder.up.3.block.0.norm1.weight', 'first_stage_model.decoder.up.3.block.0.norm1.bias', 'first_stage_model.decoder.up.3.block.0.conv1.weight', 'first_stage_model.decoder.up.3.block.0.conv1.bias', 'first_stage_model.decoder.up.3.block.0.norm2.weight', 'first_stage_model.decoder.up.3.block.0.norm2.bias', 'first_stage_model.decoder.up.3.block.0.conv2.weight', 'first_stage_model.decoder.up.3.block.0.conv2.bias', 'first_stage_model.decoder.up.3.block.1.norm1.weight', 'first_stage_model.decoder.up.3.block.1.norm1.bias', 'first_stage_model.decoder.up.3.block.1.conv1.weight', 'first_stage_model.decoder.up.3.block.1.conv1.bias', 'first_stage_model.decoder.up.3.block.1.norm2.weight', 'first_stage_model.decoder.up.3.block.1.norm2.bias', 'first_stage_model.decoder.up.3.block.1.conv2.weight', 'first_stage_model.decoder.up.3.block.1.conv2.bias', 'first_stage_model.decoder.up.3.block.2.norm1.weight', 'first_stage_model.decoder.up.3.block.2.norm1.bias', 'first_stage_model.decoder.up.3.block.2.conv1.weight', 'first_stage_model.decoder.up.3.block.2.conv1.bias', 'first_stage_model.decoder.up.3.block.2.norm2.weight', 'first_stage_model.decoder.up.3.block.2.norm2.bias', 'first_stage_model.decoder.up.3.block.2.conv2.weight', 'first_stage_model.decoder.up.3.block.2.conv2.bias', 'first_stage_model.decoder.up.3.upsample.conv.weight', 'first_stage_model.decoder.up.3.upsample.conv.bias', 'first_stage_model.decoder.norm_out.weight', 'first_stage_model.decoder.norm_out.bias', 'first_stage_model.decoder.conv_out.weight', 'first_stage_model.decoder.conv_out.bias', 'first_stage_model.quant_conv.weight', 'first_stage_model.quant_conv.bias', 'first_stage_model.post_quant_conv.weight', 'first_stage_model.post_quant_conv.bias'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"state_dict\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c63b6254-6875-48d2-95b6-cfb0e6e906ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_state_dict'"
     ]
    }
   ],
   "source": [
    "type(a['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fedbe2-23a7-484d-8afa-d70b9901836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_audio = AudioTrain()\n",
    "# dt_audio\n",
    "dt_audio = AudioTrain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9160cc0f-a9f8-4470-b5cb-549580566b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "100\n",
      "105\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "dt_audio = AudioTrain()\n",
    "dl_audio = DataLoader(dt_audio, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "for ind, item in enumerate(dl_audio):\n",
    "    if ind % 5 == 0:\n",
    "        print(ind)\n",
    "#         print()\n",
    "#     if ind >= 3:\n",
    "#         break\n",
    "    \n",
    "#     print()\n",
    "#     print(item['audio'].shape)\n",
    "# #     print(item['audio'].max())\n",
    "\n",
    "#     print(\"******\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a52b592-265d-4d7e-bfa3-a1c1d83d5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_root = \"/kuacc/users/bbiner21/Github/audioset-processing/audio_10s_npy/\"\n",
    "audio_data_paths = \"data/landscape/audio_train.txt\"\n",
    "\n",
    "with open(audio_data_paths, \"r\") as af:\n",
    "    audio_paths = af.read().splitlines() \n",
    "\n",
    "a_files = [os.path.join(aud_root, l)\n",
    "                           for l in audio_paths]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e18dcd9d-d32f-4cea-bfcb-964145580363",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in dt_audio.labels[\"audio_file_path_\"]:\n",
    "    path = f\n",
    "    temp = np.load(f,allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a4fa220-2402-414f-8818-4d83513c8ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kuacc/users/bbiner21/Github/audioset-processing/audio_10s_npy/glC1fpVTsRk.npy\n",
      "(315392, 2)\n",
      "125608\n"
     ]
    }
   ],
   "source": [
    "a = dt_audio.__getitem__(720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be6613af-44b3-4e47-a229-772614617d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167796.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a[\"audio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea2db86-4791-4617-9878-49d5c13f1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_amount = 125608 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a0e7bd6-65f3-4065-a1ac-4eedbeb2d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "track = a[\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61cc8f42-193f-4410-8336-fd34d53c44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "track = np.pad(track,((0,pad_amount),(0,0)),'constant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27a62fea-aab7-4cce-8a19-948f92546316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441000, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5896b0d9-9ee5-42ee-b190-19db4a21a215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315392, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"audio\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b3539e-8c32-4ee8-880b-c96a6fb91048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(dt_audio)):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a14c8a-84a3-49e7-8f88-8cac9d42d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_files -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0094d769-0a35-43ac-b718-c552c10541f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in a_files:\n",
    "    temp = np.load(f,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47313fba-e861-4882-ae61-4a7ea9994471",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ignite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../AudioCLIP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(sys.path)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioCLIP\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_audioclip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToTensor1D\n",
      "File \u001b[0;32m/scratch/users/bbiner21/Github/AudioCLIP/model/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mesresnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudioclip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioCLIP\n",
      "File \u001b[0;32m/scratch/users/bbiner21/Github/AudioCLIP/model/esresnet/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ESResNet\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ESResNeXt\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfbsp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ESResNetFBSP\n",
      "File \u001b[0;32m/scratch/users/bbiner21/Github/AudioCLIP/model/esresnet/base.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtv\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite_trainer\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mit\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mesresnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attention\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_audioclip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n",
      "File \u001b[0;32m/scratch/users/bbiner21/Github/AudioCLIP/ignite_trainer/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# from ignite_trainer.version import __version__\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m main, run\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_class\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interfaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AbstractNet, AbstractTransform\n",
      "File \u001b[0;32m/scratch/users/bbiner21/Github/AudioCLIP/ignite_trainer/_trainer.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtv\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mieng\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mimet\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mignite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mihan\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ignite'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../AudioCLIP')\n",
    "\n",
    "# print(sys.path)\n",
    "from model import AudioCLIP\n",
    "from utils_audioclip.transforms import ToTensor1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679f304-fe57-45a0-a8ae-a330a9930aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "392b540c-91bf-4b7d-97c8-290b6aabb773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da866624-6d70-4fd1-b751-457c555ecf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/kuacc/users/bbiner21/Github/CIFAR-10-images/train\"\n",
    "path2 = \"/kuacc/users/bbiner21/Github/CIFAR-10-images/train/airplane\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb49b2a-df54-4f85-afa5-2093a44ec385",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(path2)\n",
    "files = list(path.glob('*.jpg')) + list(path.glob('*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e85879d-799b-4026-98cb-1c843e6ad50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/kuacc/users/bbiner21/Github/CIFAR-10-images/train/airplane/1883.jpg')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aca507d2-430e-4a54-9fcc-de48e1fa79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(path)\n",
    "files = list(path.rglob('*.jpg')) + list(path.rglob('*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "519c9284-006b-4dd1-a4e4-2835c5ac3a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "097914d1-97a1-436f-a30e-78f6faeb633e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.PosixPath"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbf77e2-49f3-4b95-b36f-d55e81b3a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldm.data.lsun import LSUNChurchesTrain\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ldm.data.cifar_dataset import CifarTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95721064-2cdd-450e-8350-347e6167e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "dt_cifar = CifarTrain()\n",
    "dl_cifar = DataLoader(dt_cifar, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6725f82-d0ee-452e-865e-83c839434768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(-1.)\n",
      "tensor(1.)\n",
      "******\n",
      "1\n",
      "tensor(-0.9922)\n",
      "tensor(1.)\n",
      "******\n",
      "2\n",
      "tensor(-1.)\n",
      "tensor(1.)\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "for ind, item in enumerate(dl_cifar):\n",
    "    if ind >= 3:\n",
    "        break\n",
    "    \n",
    "    print(ind)\n",
    "    print(item['image'].min())\n",
    "    print(item['image'].max())\n",
    "\n",
    "    print(\"******\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f92c35-149b-4c7a-927b-e6516e9dc582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af6cacd-6f77-454d-9b3e-3317b632bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = LSUNChurchesTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9265af5b-8c1a-4f01-8a4d-0bf7dc2fdfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ldm.data.lsun.LSUNChurchesTrain"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f3797b-db66-4a12-a344-2ac0fb58502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dt, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59b8717-b2b0-4597-bf51-b331a8a08f93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "******\n",
      "0\n",
      "tensor(1.)\n",
      "******\n",
      "1\n",
      "tensor(1.)\n",
      "******\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for ind, item in enumerate(dl):\n",
    "    if ind >= 3:\n",
    "        break\n",
    "    print(item['image'].max())\n",
    "    print(\"******\")\n",
    "    print(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681b6b65-2768-450f-9356-d04e82122ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from six.moves import cPickle as pickle\n",
    "import os\n",
    "import platform\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "\n",
    "def load_pickle(f):\n",
    "    version = platform.python_version_tuple()\n",
    "    if version[0] == '2':\n",
    "        return  pickle.load(f)\n",
    "    elif version[0] == '3':\n",
    "        return  pickle.load(f, encoding='latin1')\n",
    "    raise ValueError(\"invalid python version: {}\".format(version))\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = load_pickle(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000,3072)\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000,data_dir=\"/datasets/cifar/cifar-10-batches-py\"):\n",
    "    \n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = data_dir\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    x_train = X_train.astype('float32')\n",
    "    x_test = X_test.astype('float32')\n",
    "\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    return x_train, y_train, X_val, y_val, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29543b0d-be87-4b73-9634-e4ced5ab1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/datasets/cifar/cifar-10-batches-py/data_batch_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c81fb6-7cdb-4069-ba5c-03789772aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = np.load(path)\n",
    "# m, s = f['mu'][:], f['sigma'][:]\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f740393e-9011-4fe3-9477-45267efe5b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3072)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 3072)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = get_CIFAR10_data()\n",
    "\n",
    "\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff38d89-a3d3-40fe-870f-7a3f9116facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2594979b-a254-422e-9b38-9e07c413a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = x_train[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a38105f6-ce68-4388-909b-7637aa123b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 3072)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7a30f38-6219-4937-b317-1614521562d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_train = (x_train.reshape(x_train.shape[0],3,32,32)).transpose(0,2,3,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a57763cc-51b2-4ead-8141-7a634a00c039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 32, 32, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9301013a-15c2-4d9b-ae32-ccaa55e316fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "image = image.reshape(3,32,32)\n",
    "image = image.transpose(1,2,0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9069e3ee-da5a-4648-bb62-a4ccc5b19c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b2e669faad0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(new_x_train[3,:])\n",
    "# plt.title(label_name[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "536dfbaa-a627-49d2-be0b-80eb7a8facab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82508d23-c58e-4925-bc78-a683930d0f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START /usr/bin/eog \"/tmp/tmp3v5gwbir.PNG\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:101174): Gtk-WARNING **: 15:22:57.479: cannot open display: \n",
      "xdg-open: no method available for opening '/tmp/tmp3v5gwbir.PNG'\n"
     ]
    }
   ],
   "source": [
    "# w, h = 512, 512\n",
    "# data = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "# data[0:256, 0:256] = [255, 0, 0] # red patch in upper left\n",
    "img = Image.fromarray(image*255, 'RGB')\n",
    "img.save('my.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db64dea5-381b-49fa-a161-f5969b862d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(image*256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taming",
   "language": "python",
   "name": "taming"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
